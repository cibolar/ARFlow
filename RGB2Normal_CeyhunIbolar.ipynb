{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RGB2Normal_CeyhunIbolar",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xV4ofDtED3AdNpf08uBYbDl4-Go5Mg6p",
      "authorship_tag": "ABX9TyPVrhXOWhr0aLhR3FmFGJyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cibolar/ARFlow/blob/master/RGB2Normal_CeyhunIbolar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75SILjvERRVR"
      },
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "!rm -r RGBD2Normal\n",
        "!git clone https://github.com/cibolar/RGBD2Normal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCfmeQJ2SRiU"
      },
      "source": [
        "/content/drive/MyDrive/RGBD2Normal/pre_trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv4wKE4k5vyM",
        "outputId": "b93d4b15-886e-4cd8-8819-8014beb3aab1"
      },
      "source": [
        "%cd /content/RGBD2Normal\n",
        "##########################\n",
        "# Test normal estimation\n",
        "# RGBD input\n",
        "# coupled with train_RGBD_ms.py\n",
        "# Jin Zeng, 20181031\n",
        "#########################\n",
        "import sys\n",
        "sys.path.append('/content/RGBD2Normal/models/')\n",
        "sys.path.append('/content/RGBD2Normal/loader/')\n",
        "sys.path.append('/content/RGBD2Normal/pre_trained/')\n",
        "\n",
        "import cv2\n",
        "import sys, os\n",
        "import torch\n",
        "import argparse\n",
        "import timeit\n",
        "import numpy as np\n",
        "import scipy.misc as misc\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from os.path import join as pjoin\n",
        "import scipy.io as io\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models import get_model, get_lossfun\n",
        "from loader import get_data_path, get_loader\n",
        "from pre_trained import get_premodel\n",
        "from utils import norm_imsave, change_channel\n",
        "from models.eval import eval_normal_pixel, eval_print\n",
        "from loader.loader_utils import png_reader_32bit, png_reader_uint8\n",
        "\n",
        "\n",
        "def test(args):\n",
        "    # Setup Model\n",
        "    # Setup the fusion model (RGB+Depth)\n",
        "    model_name_F = args.arch_F\n",
        "    model_F = get_model(model_name_F, True)  # concat and output\n",
        "    model_F = torch.nn.DataParallel(model_F, device_ids=range(torch.cuda.device_count()))\n",
        "    # Setup the map model\n",
        "    if args.arch_map == 'map_conv':\n",
        "        model_name_map = args.arch_map\n",
        "        model_map = get_model(model_name_map, True)  # concat and output\n",
        "        model_map = torch.nn.DataParallel(model_map, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "    if args.model_full_name != '':\n",
        "        # Use the full name of model to load\n",
        "        print(\"Load training model: \" + args.model_full_name)\n",
        "        checkpoint = torch.load(pjoin(args.model_savepath, args.model_full_name))\n",
        "        model_F.load_state_dict(checkpoint['model_F_state'])\n",
        "        model_map.load_state_dict(checkpoint[\"model_map_state\"])\n",
        "\n",
        "\n",
        "    # Setup image\n",
        "    if args.imgset:\n",
        "        print(\"Test on dataset: {}\".format(args.dataset))\n",
        "        data_loader = get_loader(args.dataset)\n",
        "        data_path = get_data_path(args.dataset)\n",
        "        v_loader = data_loader(data_path, split=args.test_split, img_size=(args.img_rows, args.img_cols),\n",
        "                               img_norm=args.img_norm)\n",
        "        evalloader = data.DataLoader(v_loader, batch_size=1)\n",
        "        print(\"Finish Loader Setup\")\n",
        "\n",
        "        model_F.cuda()\n",
        "        model_F.eval()\n",
        "        if args.arch_map == 'map_conv':\n",
        "            model_map.cuda()\n",
        "            model_map.eval()\n",
        "\n",
        "        sum_mean, sum_median, sum_small, sum_mid, sum_large, sum_num = [], [], [], [], [], []\n",
        "        evalcount = 0\n",
        "        with torch.no_grad():\n",
        "            for i_val, (images_val, labels_val, masks_val, valids_val, depthes_val, meshdepthes_val) in tqdm(\n",
        "                    enumerate(evalloader)):\n",
        "\n",
        "                images_val = Variable(images_val.contiguous().cuda())\n",
        "                labels_val = Variable(labels_val.contiguous().cuda())\n",
        "                masks_val = Variable(masks_val.contiguous().cuda())\n",
        "                valids_val = Variable(valids_val.contiguous().cuda())\n",
        "                depthes_val = Variable(depthes_val.contiguous().cuda())\n",
        "\n",
        "                if args.arch_map == 'map_conv':\n",
        "                    outputs_valid = model_map(torch.cat((depthes_val, valids_val[:, np.newaxis, :, :]), dim=1))\n",
        "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images_val, depthes_val,\n",
        "                                                                              outputs_valid.squeeze(1))\n",
        "                else:\n",
        "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images_val, depthes_val, valids_val)\n",
        "\n",
        "                outputs_n, pixelnum, mean_i, median_i, small_i, mid_i, large_i = eval_normal_pixel(outputs, labels_val,\n",
        "                                                                                                   masks_val)\n",
        "                outputs_norm = np.squeeze(outputs_n.data.cpu().numpy(), axis=0)\n",
        "                labels_val_norm = np.squeeze(labels_val.data.cpu().numpy(), axis=0)\n",
        "                images_val = np.squeeze(images_val.data.cpu().numpy(), axis=0)\n",
        "                images_val = images_val + 0.5\n",
        "                images_val = images_val.transpose(1, 2, 0)\n",
        "                depthes_val = np.squeeze(depthes_val.data.cpu().numpy(), axis=0)\n",
        "                depthes_val = np.transpose(depthes_val, [1, 2, 0])\n",
        "                depthes_val = np.repeat(depthes_val, 3, axis=2)\n",
        "\n",
        "                outputs_norm = change_channel(outputs_norm)\n",
        "                labels_val_norm = (labels_val_norm + 1) / 2\n",
        "                labels_val_norm = change_channel(labels_val_norm)\n",
        "\n",
        "                # if (i_val+1)%10 == 0:\n",
        "                misc.imsave(pjoin(args.testset_out_path, \"{}_MS_hyb.png\".format(i_val + 1)), outputs_norm)\n",
        "                misc.imsave(pjoin(args.testset_out_path, \"{}_gt.png\".format(i_val + 1)), labels_val_norm)\n",
        "                misc.imsave(pjoin(args.testset_out_path, \"{}_in.jpg\".format(i_val + 1)), images_val)\n",
        "                misc.imsave(pjoin(args.testset_out_path, \"{}_depth.png\".format(i_val + 1)), depthes_val)\n",
        "\n",
        "                # accumulate the metrics in matrix\n",
        "                if ((np.isnan(mean_i)) | (np.isinf(mean_i)) == False):\n",
        "                    sum_mean.append(mean_i)\n",
        "                    sum_median.append(median_i)\n",
        "                    sum_small.append(small_i)\n",
        "                    sum_mid.append(mid_i)\n",
        "                    sum_large.append(large_i)\n",
        "                    sum_num.append(pixelnum)\n",
        "                    evalcount += 1\n",
        "                    if (i_val + 1) % 10 == 0:\n",
        "                        print(\"Iteration %d Evaluation Loss: mean %.4f, median %.4f, 11.25 %.4f, 22.5 %.4f, 30 %.4f\" % (\n",
        "                            i_val + 1,\n",
        "                            mean_i, median_i, small_i, mid_i, large_i))\n",
        "\n",
        "                        # Summarize the result\n",
        "            eval_print(sum_mean, sum_median, sum_small, sum_mid, sum_large, sum_num, item='Pixel-Level')\n",
        "\n",
        "            avg_mean = sum(sum_mean) / evalcount\n",
        "            sum_mean.append(avg_mean)\n",
        "            avg_median = sum(sum_median) / evalcount\n",
        "            sum_median.append(avg_median)\n",
        "            avg_small = sum(sum_small) / evalcount\n",
        "            sum_small.append(avg_small)\n",
        "            avg_mid = sum(sum_mid) / evalcount\n",
        "            sum_mid.append(avg_mid)\n",
        "            avg_large = sum(sum_large) / evalcount\n",
        "            sum_large.append(avg_large)\n",
        "            print(\n",
        "                    \"evalnum is %d, Evaluation Image-Level Mean Loss: mean %.4f, median %.4f, 11.25 %.4f, 22.5 %.4f, 30 %.4f\" % (\n",
        "                evalcount,\n",
        "                avg_mean, avg_median, avg_small, avg_mid, avg_large))\n",
        "\n",
        "            sum_matrix = np.transpose([sum_mean, sum_median, sum_small, sum_mid, sum_large])\n",
        "            if args.model_full_name != '':\n",
        "                sum_file = args.model_full_name[:-4] + '.csv'\n",
        "\n",
        "            np.savetxt(sum_file, sum_matrix, fmt='%.6f', delimiter=',')\n",
        "            print(\"Saving to %s\" % (sum_file))\n",
        "            # end of dataset test\n",
        "    else:\n",
        "        if os.path.isdir(args.out_path) == False:\n",
        "            os.mkdir(args.out_path)\n",
        "        print(\"Read Input Image from : {}\".format(args.img_path))\n",
        "        for i in os.listdir(args.img_path):\n",
        "            if not i.endswith('.jpg'):\n",
        "                continue\n",
        "\n",
        "            print(i)\n",
        "            input_f = args.img_path + i\n",
        "            depth_f = args.depth_path + i[:-4] + '.png'\n",
        "            output_f = args.out_path + i[:-4] + '_rgbd.png'\n",
        "            img = cv2.imread(input_f)\n",
        "\n",
        "            orig_size = img.shape[:-1]\n",
        "            if args.img_rot:\n",
        "                img = np.transpose(img, (1, 0, 2))\n",
        "                img = np.flipud(img)\n",
        "                img = cv2.resize(img, (args.img_rows, args.img_cols))  # Need resize the image to model inputsize\n",
        "            else:\n",
        "                img = cv2.resize(img, (args.img_cols, args.img_rows))  # Need resize the image to model inputsize\n",
        "\n",
        "            img = img.astype(np.float)\n",
        "            if args.img_norm:\n",
        "                img = (img - 128) / 255\n",
        "            # NHWC -> NCHW\n",
        "            img = img.transpose(2, 0, 1)\n",
        "            img = np.expand_dims(img, 0)\n",
        "            img = torch.from_numpy(img).float()\n",
        "\n",
        "            if args.img_rot:\n",
        "                depth = png_reader_32bit(depth_f, (args.img_rows, args.img_cols))\n",
        "                depth = np.transpose(depth, (1, 0))\n",
        "                depth = np.flipud(depth)\n",
        "                # valid = png_reader_uint8(mask_f, (args.img_rows,args.img_cols))\n",
        "                # valid = np.transpose(valid, (1,0))\n",
        "                # valid = np.flipud(valid)\n",
        "            else:\n",
        "                depth = png_reader_32bit(depth_f, (args.img_rows, args.img_cols))\n",
        "                # valid = png_reader_uint8(mask_f, (args.img_rows,args.img_cols))\n",
        "\n",
        "            depth = depth.astype(float)\n",
        "            # Please change to the scale so that scaled_depth=1 corresponding to real 10m depth\n",
        "            # matterpot depth=depth/40000  scannet depth=depth/10000\n",
        "            depth = depth / (args.d_scale)\n",
        "            if depth.ndim == 3:  # to dim 2\n",
        "                depth = depth[:, :, 0]\n",
        "                # if valid.ndim == 3: #to dim 2\n",
        "            #     valid = valid[:,:,0]\n",
        "\n",
        "            # valid = 1-depth\n",
        "            # valid[valid>1] = 1\n",
        "            valid = (depth > 0.0001).astype(float)\n",
        "            # valid = depth.astype(float)\n",
        "            depth = depth[np.newaxis, :, :]\n",
        "            depth = np.expand_dims(depth, 0)\n",
        "            valid = np.expand_dims(valid, 0)\n",
        "            depth = torch.from_numpy(depth).float()\n",
        "            valid = torch.from_numpy(valid).float()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                model_F.cuda()\n",
        "                model_F.eval()\n",
        "                if args.arch_map == 'map_conv':\n",
        "                    model_map.cuda()\n",
        "                    model_map.eval()\n",
        "                images = Variable(img.contiguous().cuda())\n",
        "                depth = Variable(depth.contiguous().cuda())\n",
        "                valid = Variable(valid.contiguous().cuda())\n",
        "            else:\n",
        "                images = Variable(img)\n",
        "                depth = Variable(depth)\n",
        "                valid = Variable(valid)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                if args.arch_map == 'map_conv':\n",
        "                    outputs_valid = model_map(torch.cat((depth, valid[:, np.newaxis, :, :]), dim=1))\n",
        "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images, depth,\n",
        "                                                                              outputs_valid.squeeze(1))\n",
        "                else:\n",
        "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images, depth, outputs_valid)\n",
        "\n",
        "            outputs_norm = norm_imsave(outputs)\n",
        "            outputs_norm = np.squeeze(outputs_norm.data.cpu().numpy(), axis=0)\n",
        "            # outputs_norm = misc.imresize(outputs_norm, orig_size)\n",
        "            outputs_norm = np.array(change_channel(outputs_norm))\n",
        "            outputs_norm = outputs_norm.transpose(1, 2, 0)\n",
        "            outputs_norm = (255*outputs_norm).astype(np.uint8)\n",
        "            cv2.imwrite(output_f, outputs_norm)\n",
        "        print(\"Complete\")\n",
        "        # end of test on no dataset images"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/RGBD2Normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahy2q6NJ51BP",
        "outputId": "47c5cbc3-a009-42af-82f3-962f0dc1b02f"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='Params')\n",
        "parser.add_argument('--arch_RGB', nargs='?', type=str, default='vgg_16_in',\n",
        "                    help='Architecture for RGB to use [\\'vgg_16,vgg_16_in etc\\']')\n",
        "parser.add_argument('--arch_D', nargs='?', type=str, default='unet_3_mask_in',\n",
        "                    help='Architecture for Depth to use [\\'unet_3, unet_3_mask, unet_3_mask_in etc\\']')\n",
        "parser.add_argument('--arch_F', nargs='?', type=str, default='fconv_ms',\n",
        "                    help='Architecture for Fusion to use [\\'fconv,fconv_in, fconv_ms etc\\']')\n",
        "parser.add_argument('--arch_map', nargs='?', type=str, default='map_conv',\n",
        "                    help='Architecture for confidence map to use [\\'mask, map_conv etc\\']')\n",
        "parser.add_argument('--model_savepath', nargs='?', type=str, default='./checkpoint/FCONV_MS',\n",
        "                    help='Path for model saving [\\'checkpoint etc\\']')\n",
        "parser.add_argument('--model_full_name', nargs='?', type=str, default='',\n",
        "                    help='The full name of the model to be tested.')\n",
        "\n",
        "parser.add_argument('--dataset', nargs='?', type=str, default='matterport',\n",
        "                    help='Dataset to use [\\'nyuv2, matterport, scannet, etc\\']')\n",
        "parser.add_argument('--test_split', nargs='?', type=str, default='', help='The split of dataset in testing')\n",
        "\n",
        "parser.add_argument('--loss', nargs='?', type=str, default='l1',\n",
        "                    help='Loss type: cosine, l1')\n",
        "parser.add_argument('--model_num', nargs='?', type=str, default='2',\n",
        "                    help='Checkpoint index [\\'1,2,3, etc\\']')\n",
        "parser.add_argument('--img_rows', nargs='?', type=int, default=256,\n",
        "                    help='Height of the input image, 256(mt), 240(nyu)')\n",
        "parser.add_argument('--img_cols', nargs='?', type=int, default=320,\n",
        "                    help='Width of the input image, 320(yinda and nyu)')\n",
        "\n",
        "parser.add_argument('--testset', dest='imgset', action='store_true',\n",
        "                    help='Test on set from dataloader, decided by --dataset | True by default')\n",
        "parser.add_argument('--no_testset', dest='imgset', action='store_false',\n",
        "                    help='Test on single image | True by default')\n",
        "parser.set_defaults(imgset=True)\n",
        "parser.add_argument('--testset_out_path', nargs='?', type=str, default='./result/mt_clean_small',\n",
        "                    help='Path of the output normal')\n",
        "\n",
        "parser.add_argument('--img_path', nargs='?', type=str, default='../Depth2Normal/Dataset/normal/',\n",
        "                    help='Path of the input image')\n",
        "parser.add_argument('--depth_path', nargs='?', type=str, default='../Depth2Normal/Dataset/normal/',\n",
        "                    help='Path of the input image, mt_data_clean!!!!!!!!!')\n",
        "parser.add_argument('--ir_path', nargs='?', type=str, default='../Depth2Normal/Dataset/ir_mask/',\n",
        "                    help='Path of the input image, mt_data_clean!!!!!!!!!')\n",
        "parser.add_argument('--out_path', nargs='?', type=str, default='../Depth2Normal/Dataset/normal/',\n",
        "                    help='Path of the output normal')\n",
        "parser.add_argument('--d_scale', nargs='?', type=int, default=40000,\n",
        "                    help='Depth scale for depth input. Set the scale to make the 1 in scaled depth equal to 10m.\\\n",
        "                      Only valid testing using image folder')\n",
        "\n",
        "parser.add_argument('--img_norm', dest='img_norm', action='store_true',\n",
        "                    help='Enable input image scales normalization [0, 1] | True by default')\n",
        "parser.add_argument('--no-img_norm', dest='img_norm', action='store_false',\n",
        "                    help='Disable input image scales normalization [0, 1] | True by default')\n",
        "parser.set_defaults(img_norm=True)\n",
        "\n",
        "parser.add_argument('--img_rotate', dest='img_rot', action='store_true',\n",
        "                    help='Enable input image transpose | False by default')\n",
        "parser.add_argument('--no-img_rotate', dest='img_rot', action='store_false',\n",
        "                    help='Disable input image transpose | False by default')\n",
        "\n",
        "parser.set_defaults(img_rot=False)\n",
        "\n",
        "!mkdir /content/RGBD2Normal/result\n",
        "args = parser.parse_args(\"\")\n",
        "args.arch_F = 'fconv_ms'\n",
        "args.arch_map = 'map_conv'\n",
        "args.imgset = False\n",
        "args.img_path = '/content/RGBD2Normal/sample_pic/mt_rgb/'\n",
        "args.depth_path = '/content/RGBD2Normal/sample_pic/mt_depth/'\n",
        "args.d_scale = 40000\n",
        "args.img_rows = 256\n",
        "args.img_cols = 320\n",
        "args.model_savepath = '/content/drive/MyDrive/RGBD2Normal/checkpoint/FCONV_MS/'\n",
        "args.model_full_name = 'fconv_ms_matterport_l1_2_hybrid_best.pkl'\n",
        "args.out_path = '/content/RGBD2Normal/result/demo_rgbd_mp/'\n",
        "\n",
        "test(args)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load training model: fconv_ms_matterport_l1_2_hybrid_best.pkl\n",
            "Read Input Image from : /content/RGBD2Normal/sample_pic/mt_rgb/\n",
            "a250e8fe53bc4025816b3c48a34c7367_i1_0.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0affd60e9e4249858dc9bf84639fe86f_i1_2.jpg\n",
            "9136c9c351cd4e4a8091054b693b0ca7_i1_4.jpg\n",
            "430edfa71f1441e69c9479fc0a954818_i1_4.jpg\n",
            "Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijHi6i4IUiPa"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}